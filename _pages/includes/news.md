
# ğŸ”¥ News
<style>
  .scrollable {
    max-height: 260px; /* è®¾ç½®æœ€å¤§é«˜åº¦ */
    overflow-y: scroll; /* è®¾ç½®å‚ç›´æ»šåŠ¨æ¡ */
  }
</style>

- *2024.08*: &nbsp;ğŸ“ **Raconteur** was accepted by NDSS 2025! Raconteur is the first tool using Large Language Models (LLMs) to explain shell commands clearly. It provides detailed insights into command functions and purposes, aligning with MITRE ATT&CK standards. Equipped with professional cybersecurity knowledge, Raconteur delivers accurate explanations. A documentation retriever helps understand new commands. Tested extensively, Raconteur offers unique insights, helping security analysts better understand command intentions. [website](https://raconteur-ndss.github.io/).
- *2024.08*: &nbsp;ğŸ“ **Legilimens** was accepted by CCS 2024! A new SOTA of the LLM unsafe moderation technique, with significantly improvement in efficiency. Congratulations to Jialin and Dr. Deng.
- *2024.05*: &nbsp;ğŸ“ **SafeGen** was accepted by CCS 2024! As T2I technologies advance, their misuse to generate sexually explicit content has become a major concern. SafeGen effectively mitigates this by removing any explicit visual representations from the model, making it safe regardless of the adversarial text input, outperforming eight other protection approaches. SafeGen adjusts the model's visual self-attention layers to ensure that the high-quality production of benign images is not compromised. More information are on our [code](https://github.com/LetterLiGo/SafeGen_CCS2024).
- *2024.05*: &nbsp;ğŸ”¥ **SafeEar** got accepted by CCS 2024! To our knowledge, this is the 1st content privacy-preserving audio deepfake detection framework. Since audio deepfakes and user privacy concerns have been increasingly significant societal issues, we demonstrate how to achieve reliable deepfake detection while preventing both machine and human adversaries from eavesdropping on sensitive user speech content. To facilitate future research, we also develop a comprehensive multilingual deepfake datasets (more than 1,500,000 genuine & deepfake audio samples) using advanced TTS/VC techniques. Please check out our [demo page](https://letterligo.github.io/SafeEar/).
<!-- - *2024.02*: &nbsp;ğŸ‰ I am so excited to be awarded the NDSS 2024 Student Grant. -->
- *2023.12*: &nbsp;ğŸ”¥ One Vision-Language Model Security paper submitted to S&P (Oakland) 2024 (Core A*, Big4, CCF-A).
<!-- - *2023.09*: &nbsp;ğŸ€ One LLM-oriented paper submitted to NSDI 2024 (CCF-A, one of the best conference on network and system related topics). -->
- *2023.08*: &nbsp;ğŸ‰ **VRifle** got accepted by NDSS 2024! We demonstrate how to achieve completely inaudible adversarial perturbation attack via ultrasound, which achieves the farthest attack range (~10 meters away) and most universal capability (1 perturb. can tamper with >28,000 benign samples). Our novel ultrasonic transformation model can be generalized to other modality of attacks, such as laser, electromagentic.
- *2023.08*: &nbsp;ğŸ”¥ I attend USENIX Security 2023 Symposium and present our work **NormDetect** in person.
- *2023.07*: &nbsp;ğŸ˜„ Our practical backdoor attack (**SMA**) against ASR models is accepted by ACM MM 2023!
- *2022.09*: &nbsp;ğŸ‰ **Tuner** and **UltraBD** are accepted by IoT-J 2023 and ICPADS 2022! We demonstrate a practical inaudible backdoor attacks against the speaker recognition systems.
- *2022.07*: &nbsp;ğŸ’ªğŸ» **NormDetect** is accepted by USENIX Security 2023! We rethink the challenging topic of defending against inaudible voice attacks, and present a software-based mitigation that can instantly protect legacy and future devices in an actionable and practical manner, which is verified on 24 mainstream smart devices with voice interfaces.
- *2021.07*: &nbsp;ğŸ‰ **PROLE Score** is accepted by USENIX Security 2022! "OK Siri" or "Hey Google"? We conduct an extensive voiceprint security measurement. Our findings and designed metrics shall aid manufactures and users to DIY highly secure voiceprint phrases.
- *2020.12*: &nbsp;ğŸ”¥ **EarArray** is accepted by NDSS 2021! We uncover the inherent physical properties of inaudible attack, i.e. ultrasound field distributions, and redesign microphone arrays for accurate detection and attack localization.
